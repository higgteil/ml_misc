# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DIonLvMS6sEO21zL7BpejPjnIclEM9SK
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Oct 16 18:22:03 2021

"""

from sklearn.base import BaseEstimator, ClassifierMixin
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.neural_network import BernoulliRBM
from sklearn import linear_model, datasets, preprocessing
from sklearn.pipeline import Pipeline 
from sklearn.metrics import classification_report, accuracy_score
from sklearn import metrics
from sklearn.model_selection import train_test_split, RandomizedSearchCV


    
    

class RBM_EmbeddingLogisticRegression(BaseEstimator, ClassifierMixin):
    """Fits a logistic regression model on tree embeddings.
    """
    def __init__(self, **kwargs):
        self.kwargs = kwargs
        self.binarizer = preprocessing.Binarizer(threshold=0.01,copy=True)
        self.imputer=SimpleImputer(missing_values=np.nan )
        self.rbm = BernoulliRBM(random_state=0)
        self.lr = LogisticRegression()
        self.bin = OneHotEncoder()
        self.cv_r = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
        self.cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=8)
        self.params = dict()
        
        self.pipe = Pipeline(
                    steps=[
                        ('impute', self.imputer), 
                        ('binarize', self.binarizer),
                        ('rbm',self.rbm),
                        ('lr', self.lr)
                        ])
        self.gs = RandomizedSearchCV(self.pipe, self.params)

    
    # def cv_split(self, X, y):
    #     X_train, X_test, y_train,y_test = train_test_split(X,y, stratify =y, test_size=0.25, random_state=1)
    #     return  X_train, X_test, y_train,y_test

    
    def fit(self, X,y,*args):
        def cv_split(X, y):
            X_train, X_test, y_train,y_test = train_test_split(X,y, stratify =y, test_size=0.25, random_state=1)
            return  X_train, X_test, y_train,y_test
        
        X_train, X_test, y_train,y_test = cv_split(X,y)
        print('pipe with parameters: \n'.format(self.pipe))
        self.gs = RandomizedSearchCV(self.pipe, *args)
        print('grid searching ... : %s' % self.gs)
        grid = self.gs.fit(X_train, y_train)
        print('Training set score: ' + str(grid.score(X_train, y_train)))  
        
        return grid, X_train, X_test, y_train,y_test
    
    def predict(self, X_test, y_test=None):
        y_pred = self.gs.predict(X)
        test_set_score = grid.score(X_test,y_test)
        print('Test set score: {}'.format(np.round(np.mean(test_set_score),3)))

        return y_pred
    
    def clf_report(self,y_test, y_pred):
        print("Logistic Regression using RBM features: \n%s\n" %
              metrics.classification_report(y_test, y_pred))
    
    def cv_score(self, X, y):
        X = np.array(X)
        cross_val_scores  = cross_val_score(grid, X, y,cv=self.cv,scoring='roc_auc')
        print('cross-val-score: {}'.format(np.round(np.mean(cross_val_scores),2)))
              

params = {
            'impute__strategy': ['mean', 'median','most_frequent'],
            'binarize__threshold': [0.01, 0.05, 0.1, 0.5, 0.8],
            'rbm__n_components': [5, 10, 20, 50, 100, 200],
           	'lr__C': [0.001,0.01, 0.1, 1, 2, 3],
             }
    
model = RBM_EmbeddingLogisticRegression()
model.fit(X,y, params )
model.predict(X_test,y_test)    
model.cv_score(X,y)